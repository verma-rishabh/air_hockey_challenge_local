{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:44:17\n"
     ]
    }
   ],
   "source": [
    "from air_hockey_challenge.framework.air_hockey_challenge_wrapper import AirHockeyChallengeWrapper\n",
    "\n",
    "from air_hockey_challenge.environments.iiwas.env_hitting import AirHockeyHit\n",
    "from air_hockey_agent.agent_builder_ddpg_hit import build_agent\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AirHockeyChallengeWrapper(env=\"7dof-hit\", interpolation_order=3, debug=False)\n",
    "# policy = build_agent(env.env_info)\n",
    "policy = build_agent(env.env_info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, done = env.reset(), False\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = policy.draw_action(np.array(state))\n",
    "\n",
    "# Perform action\n",
    "next_state, reward, done, _ = env.step(action)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.01092272e+00,  3.36833679e-02, -5.17195762e-03, -3.78042692e-01,\n",
       "       -2.55376565e-01, -2.57616585e-01, -7.34483652e-02, -2.05689578e-01,\n",
       "        8.63480357e-02, -1.84427438e+00, -3.66915806e-02,  9.60816705e-01,\n",
       "       -2.35076631e-02, -1.45727843e+01, -2.55890526e-01,  1.14641582e+01,\n",
       "       -5.63309576e-02,  8.01443930e+00, -5.58031518e-02,  6.08638418e+00,\n",
       "        2.37373363e+00,  3.90604999e-03,  1.64211777e-01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.6570691 , -0.01602344,  0.17382842]),\n",
       " array([[-0.8559957 , -0.03371352,  0.51588251],\n",
       "        [-0.06303962,  0.99723179, -0.03943039],\n",
       "        [-0.5131251 , -0.06627328, -0.85575141]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.get_ee_pose(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from air_hockey_challenge.utils.kinematics import inverse_kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_pos = np.array([0.78,0.00,0.181])\n",
    "_,x = inverse_kinematics(policy.robot_model, policy.robot_data,des_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.32562380e-17, -3.35883047e-02, -1.24463119e-17, -1.76999920e+00,\n",
       "       -1.03464779e-17,  7.61726915e-01,  4.75070145e-21])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = np.zeros((2,7))\n",
    "action[0,:] = x[1]\n",
    "action[1,:] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state, reward, done, _ = env.step(action)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.64010856, 0.01666328, 0.1527822 ]),\n",
       " array([[-0.86484366, -0.11688435,  0.48824532],\n",
       "        [-0.12211214,  0.9922888 ,  0.02124982],\n",
       "        [-0.48696414, -0.04124291, -0.87244768]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.get_ee_pose(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'table': {'length': 1.948, 'width': 1.038, 'goal_width': 0.25},\n",
       " 'puck': {'radius': 0.03165},\n",
       " 'mallet': {'radius': 0.04815},\n",
       " 'n_agents': 2,\n",
       " 'robot': {'n_joints': 7,\n",
       "  'ee_desired_height': 0.1645,\n",
       "  'joint_vel_limit': array([[-1.48352986, -1.48352986, -1.74532925, -1.30899694, -2.26892803,\n",
       "          -2.35619449, -2.35619449],\n",
       "         [ 1.48352986,  1.48352986,  1.74532925,  1.30899694,  2.26892803,\n",
       "           2.35619449,  2.35619449]]),\n",
       "  'joint_acc_limit': array([[-14.83529864, -14.83529864, -17.45329252, -13.08996939,\n",
       "          -22.68928028, -23.5619449 , -23.5619449 ],\n",
       "         [ 14.83529864,  14.83529864,  17.45329252,  13.08996939,\n",
       "           22.68928028,  23.5619449 ,  23.5619449 ]]),\n",
       "  'base_frame': [array([[ 1.  ,  0.  ,  0.  , -1.51],\n",
       "          [ 0.  ,  1.  ,  0.  ,  0.  ],\n",
       "          [ 0.  ,  0.  ,  1.  , -0.1 ],\n",
       "          [ 0.  ,  0.  ,  0.  ,  1.  ]]),\n",
       "   array([[-1.  ,  0.  ,  0.  ,  1.51],\n",
       "          [ 0.  , -1.  ,  0.  ,  0.  ],\n",
       "          [ 0.  ,  0.  ,  1.  , -0.1 ],\n",
       "          [ 0.  ,  0.  ,  0.  ,  1.  ]])],\n",
       "  'universal_height': 0.0645,\n",
       "  'control_frequency': 50,\n",
       "  'joint_pos_limit': array([[-2.96706, -2.0944 , -2.96706, -2.0944 , -2.96706, -2.0944 ,\n",
       "          -3.05433],\n",
       "         [ 2.96706,  2.0944 ,  2.96706,  2.0944 ,  2.96706,  2.0944 ,\n",
       "           3.05433]]),\n",
       "  'robot_model': <mujoco._structs.MjModel at 0x7f9b49917eb0>,\n",
       "  'robot_data': <mujoco._structs.MjData at 0x7f9b49917ab0>},\n",
       " 'puck_pos_ids': [0, 1, 2],\n",
       " 'puck_vel_ids': [3, 4, 5],\n",
       " 'joint_pos_ids': [6, 7, 8, 9, 10, 11, 12],\n",
       " 'joint_vel_ids': [13, 14, 15, 16, 17, 18, 19],\n",
       " 'opponent_ee_ids': [20, 21, 22],\n",
       " 'dt': 0.02,\n",
       " 'rl_info': <mushroom_rl.core.environment.MDPInfo at 0x7f9c2b2c7730>,\n",
       " 'constraints': <air_hockey_challenge.constraints.constraints.ConstraintList at 0x7f9b49900e80>,\n",
       " 'env_name': '7dof-hit'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1645"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env_info['robot']['ee_desired_height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env._mdp_info.observation_space.shape\n",
    "# env.env_info['rl_info'].action_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23,)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.base_env.env_info[\"rl_info\"].observation_space.low.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pos_max = env.env_info['robot']['joint_pos_limit'][1]\n",
    "vel_max = env.env_info['robot']['joint_vel_limit'][1] \n",
    "max_ = np.stack([pos_max,vel_max])\n",
    "max_action  =   max_.reshape(14,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.96706   , 2.0944    , 2.96706   , 2.0944    , 2.96706   ,\n",
       "       2.0944    , 3.05433   , 1.48352986, 1.48352986, 1.74532925,\n",
       "       1.30899694, 2.26892803, 2.35619449, 2.35619449])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.    0.    0.   -1.51]\n",
      " [ 0.    1.    0.    0.  ]\n",
      " [ 0.    0.    1.   -0.1 ]\n",
      " [ 0.    0.    0.    1.  ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[169], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mair_hockey_challenge\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransformations\u001b[39;00m \u001b[39mimport\u001b[39;00m world_to_robot\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(env\u001b[39m.\u001b[39menv_info[\u001b[39m'\u001b[39m\u001b[39mrobot\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mbase_frame\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m x \u001b[39m=\u001b[39m world_to_robot(env\u001b[39m.\u001b[39;49menv_info[\u001b[39m'\u001b[39;49m\u001b[39mrobot\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mbase_frame\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m],env\u001b[39m.\u001b[39;49menv_info[\u001b[39m'\u001b[39;49m\u001b[39mtable\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mlength\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/SS23/DeepLearning Lab/Project/air_hockey_challenge_local/air_hockey_challenge/utils/transformations.py:59\u001b[0m, in \u001b[0;36mworld_to_robot\u001b[0;34m(base_frame, translation, rotation)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39mTransfrom position and rotation (optional) from the world frame to the robot's base frame\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m target \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39meye(\u001b[39m4\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m target[:\u001b[39mlen\u001b[39;49m(translation), \u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m translation\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m rotation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     target[:\u001b[39m3\u001b[39m, :\u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m rotation\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "from air_hockey_challenge.utils.transformations import world_to_robot\n",
    "print(env.env_info['robot']['base_frame'][0])\n",
    "x = world_to_robot(env.env_info['robot']['base_frame'][0],env.env_info['table']['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0921, 5.6445, 0.0062, 4.3529, 1.1709],\n",
      "        [5.9289, 2.4195, 4.5575, 0.4351, 1.1163],\n",
      "        [3.7259, 0.4411, 2.3772, 3.0531, 3.1126]], grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "loss = torch.nn.MSELoss(reduction='none')\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5,requires_grad=True)\n",
    "output = loss(input, target)\n",
    "# print(output.detach().numpy())\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[207], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output\u001b[39m.\u001b[39;49mbackward(torch\u001b[39m.\u001b[39;49mones_like(\u001b[39minput\u001b[39;49m)\u001b[39m*\u001b[39;49m\u001b[39m1.0\u001b[39;49m,retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mdata)\n\u001b[1;32m      3\u001b[0m \u001b[39m# output.grad.data.zero_()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/challenge/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/challenge/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "output.backward(torch.ones_like(input)*1.0,retain_graph=True)\n",
    "print(output.grad.data)\n",
    "# output.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0921, 5.6445, 0.0062, 4.3529, 1.1709],\n",
      "        [5.9289, 2.4195, 4.5575, 0.4351, 1.1163],\n",
      "        [3.7259, 0.4411, 2.3772, 3.0531, 3.1126]], grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.50000005e-01 -1.01327613e-38  1.64500044e-01]\n",
      "0.1645\n"
     ]
    }
   ],
   "source": [
    "ee_pos = policy.get_ee_pose(state)[0] \n",
    "print(ee_pos)\n",
    "des_z = env.env_info['robot']['ee_desired_height']\n",
    "print(des_z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('challenge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6100d8334917db35c4ec7cf716c3100bfc66eb35e85e153ba7e378d404aaa54d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
