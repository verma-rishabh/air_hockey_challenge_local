{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorboard_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"replay_buffer/data.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_files': ['state.npy',\n",
       "  'action.npy',\n",
       "  'next_state.npy',\n",
       "  'reward.npy',\n",
       "  'not_done.npy'],\n",
       " 'files': ['state', 'action', 'next_state', 'reward', 'not_done'],\n",
       " 'allow_pickle': False,\n",
       " 'max_header_size': 10000,\n",
       " 'pickle_kwargs': {'encoding': 'ASCII', 'fix_imports': True},\n",
       " 'zip': <zipfile.ZipFile file=<_io.BufferedReader name='replay_buffer/data.npz'> mode='r'>,\n",
       " 'f': <numpy.lib.npyio.BagObj at 0x7f522fa47e80>,\n",
       " 'fid': <_io.BufferedReader name='replay_buffer/data.npz'>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = x[\"state\"]\n",
    "next_state = x[\"next_state\"]\n",
    "reward = x[\"reward\"]\n",
    "not_done = x[\"not_done\"]\n",
    "action = x[\"action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59000, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "\tdef __init__(self, state_dim, action_dim, max_size=int(1e6)):\n",
    "\t\tself.max_size = max_size\n",
    "\t\tself.ptr = 59000\n",
    "\t\tself.size = 59000\n",
    "\n",
    "\t\tself.state = state\n",
    "\t\tself.action = action\n",
    "\t\tself.next_state = next_state\n",
    "\t\tself.reward = reward\n",
    "\t\tself.not_done = not_done\n",
    "\n",
    "\t\tself.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\tdef add(self, state, action, next_state, reward, done):\n",
    "\t\tself.state[self.ptr] = state\n",
    "\t\tself.action[self.ptr] = action\n",
    "\t\tself.next_state[self.ptr] = next_state\n",
    "\t\tself.reward[self.ptr] = reward\n",
    "\t\tself.not_done[self.ptr] = 1. - done\n",
    "\n",
    "\t\tself.ptr = (self.ptr + 1) % self.max_size\n",
    "\t\tself.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "\n",
    "\tdef sample(self, batch_size):\n",
    "\t\tind = np.random.randint(0, self.size, size=batch_size)\n",
    "\n",
    "\t\treturn (\n",
    "\t\t\ttorch.FloatTensor(self.state[ind]).to(self.device),\n",
    "\t\t\ttorch.FloatTensor(self.action[ind]).to(self.device),\n",
    "\t\t\ttorch.FloatTensor(self.next_state[ind]).to(self.device),\n",
    "\t\t\ttorch.FloatTensor(self.reward[ind]).to(self.device),\n",
    "\t\t\ttorch.FloatTensor(self.not_done[ind]).to(self.device)\n",
    "\t\t)\n",
    "\t\n",
    "\tdef save(self,filename):\n",
    "\t\tnp.savez(filename,state = self.state[:self.size,::],action = self.action[:self.size,::],\\\n",
    "\t\t\tnext_state = self.next_state[:self.size,::],reward = self.reward[:self.size,::],not_done =self.not_done[:self.size,::])\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:44:17\n"
     ]
    }
   ],
   "source": [
    "from air_hockey_challenge.framework.air_hockey_challenge_wrapper import AirHockeyChallengeWrapper\n",
    "from air_hockey_agent.agent_builder_ddpg_hit import build_agent\n",
    "# from air_hockey_challenge.environments.planar.hit import AirHockeyHit\n",
    "from tensorboard_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AirHockeyChallengeWrapper(env=\"7dof-hit\", interpolation_order=3, debug=False)\n",
    "# policy = build_agent(env.env_info)\n",
    "policy = build_agent(env.env_info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(23, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"/run/media/luke/Data/uni/SS2023/DL Lab/Project/qualifying/DDPG\"\n",
    "tensorboard_dir=main_dir + \"/tensorboard/\"\n",
    "tensorboard = Evaluation(tensorboard_dir, \"train\", [\"critic_loss\",\"actor_loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1500):\n",
    "    critic_loss=np.nan\n",
    "    actor_loss=np.nan\n",
    "    critic_loss,actor_loss = policy.train(replay_buffer,batch_size= 512)\n",
    "    tensorboard.write_episode_data(epoch, eval_dict={ \"critic_loss\" : critic_loss,\\\n",
    "                \"actor_loss\":actor_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.save(main_dir + f\"/models/DDPG-v0_air-hockey_0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('challenge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6100d8334917db35c4ec7cf716c3100bfc66eb35e85e153ba7e378d404aaa54d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
